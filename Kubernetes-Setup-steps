14 Steps to Install kubernetes on Ubuntu 18.04 and 16.04 (“hashicorp/bionic64”)

In this article on 14 Steps to Install kubernetes on Ubuntu 18.04 and 16.04 we are going to create Kubernetes cluster along with kubeadm on Ubuntu 18.04 (The same steps can be used for the Ubuntu 16.04 as well)
kubeadm is command line tool to interact with kubernetes cluster. Kubeadm relies on fast deployment feature of Docker and running the system services of kubernetes master and etcd server as container.

We are going to use two nodes
1. Master node - Ubuntu 18.04
2. Worker node - Ubuntu 18.04
Prerequisites

* Reading time is about 20 minutes
* Vagrant 2.2.7 or latest - For installation instruction click here
* VM VirtualBox - For installation instruction click here

Step 1 - Start your vagrant box

As a minimum requirement for kubernetes installation we need -
1. Master Node - 2 cpus, 2 GB Memory
2. Worker Node - 1 cpu, 1 GB Memory
Use following Vagrantfile to spin up your vagrant box

#Make Vagrantfile as below
Bhaglals-MacBook-Pro:vagrant Kapar$ cat Vagrantfile 
Vagrant.configure("2") do |config|
  config.vm.define "master" do |master|
    master.vm.box_download_insecure = true    
    master.vm.box = "hashicorp/bionic64"
    master.vm.network "private_network", ip: "100.0.0.1"
    master.vm.hostname = "master"
    master.vm.provider "virtualbox" do |v|
      v.name = "master"
      v.memory = 2048
      v.cpus = 2
    end
  end

  config.vm.define "worker" do |worker|
    worker.vm.box_download_insecure = true 
    worker.vm.box = "hashicorp/bionic64"
    worker.vm.network "private_network", ip: "100.0.0.2"
    worker.vm.hostname = "worker"
    worker.vm.provider "virtualbox" do |v|
      v.name = "worker"
      v.memory = 1024
      v.cpus = 1
    end
  end

end

Step 2 - Update host files on both master and worker node

master node - SSH into the master node
vagrant ssh master

Add host entry for master as well as worker node
sudo vi /etc/hosts

100.0.0.1 master.com master
100.0.0.2 worker.com worker

worker node - SSH into the master node

vagrant ssh worker

 Add host entry for master as well as worker node
sudo vi /etc/hosts

100.0.0.1 master.com master
100.0.0.2 worker.com worker

 Ping from each other
ping worker/master
64 bytes from worker.com (100.0.0.1): icmp_seq=1 ttl=64 time=0.462 ms
64 bytes from worker.com (100.0.0.2): icmp_seq=2 ttl=64 time=0.686 ms

Step 3 - Install Docker on both master and worker node
You need to install Docker on both the node.
sudo apt-get update

sudo apt install docker.io

 Enable and start docker
sudo systemctl enable docker

Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /lib/systemd/system/docker.service.

sudo systemctl start  docker

 Check the docker service status
sudo systemctl status docker

docker.service - Docker Application Container Engine
   Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
   Active: active (running) since Thu 2021-04-23 19:10:59 UTC; 4s ago
     Docs: https://docs.docker.com

 Step 4 - Disable the firewall and turnoff the “swapping”

sudo ufw disable
Firewall stopped and disabled on system startup

sudo swapoff -a

Step 5 - Install “apt-transport-https” package

sudo apt-get update && sudo apt-get install -y apt-transport-https
 
Step 6 - Download the public keys for accessing pkgs on google cloud

curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
OK

Step 7 - Add kubernetes repo to both

sudo bash -c 'echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" > /etc/apt/sources.list.d/kubernetes.list'

Step 8 - Install kubernetes on both

sudo apt-get update && sudo apt-get install -y kubelet kubeadm kubectl

Step 9 - Enable and Start kubelet

Alright now we have installed the kubernetes, now we need to enable the kubelet support for both master as well worker node
sudo systemctl enable kubelet

sudo systemctl start kubelet
 Step 10 - Initialize the kubernetes cluster

Okay now we have reach to point where we have done all the prerequisite for initializing the kubernetes cluste

Let’s run the kubernetes initialization command on only on master
sudo kubeadm init --apiserver-advertise-address=100.0.0.1 --pod-network-cidr=10.244.0.0/16


Note down kubeadm join command which we are going to use from worker node to join the master node using token.
kubeadm join 100.0.0.1:6443 --token 45xxxxxukw2ckwwk2 \ --discovery-token-ca-cert-hash sha256:cca3de1a7aa0xxxxxxxxxe1f6a1ab8badc53e00731b2be5617d80 

Step 11 - Move kube config file to current user (only run on master)

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


Step 12 - Apply CNI from kube-flannel.yml(only run on master)

 Making containers accessible to each other through networking, we need to set up the network for container communication.

Get the CNI(container network interface) configuration from flannel
wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml



Note - But since we are working on the VMs so we need to check our Ethernet interfaces first. Look out for the Ethernet i.e. eth1 which has a ip address 100.0.0.1(this is the ip address which we used in vagrant file)
ip a s
1: lo: <LOOPBACK,UP,LOWER_UP>
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 08:00:27:bb:14:75 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 08:00:27:fb:48:77 brd ff:ff:ff:ff:ff:ff
    inet 100.0.0.1
4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP>

Now we need to add the extra args for eth1 in kube-flannel.yml
vi kube-flannel.yml

Searche for - “flanneld”
In the args section add : - -iface=eth1
- --iface=eth1
        args:
        - --ip-masq
        - --kube-subnet-mgr
        - --iface=eth1


Apply the flannel configuration

kubectl apply -f kube-flannel.yml

podsecuritypolicy.policy/psp.flannel.unprivileged created
clusterrole.rbac.authorization.k8s.io/flannel created
clusterrolebinding.rbac.authorization.k8s.io/flannel created
serviceaccount/flannel created
configmap/kube-flannel-cfg created
daemonset.apps/kube-flannel-ds-amd64 created
daemonset.apps/kube-flannel-ds-arm64 created
daemonset.apps/kube-flannel-ds-arm created
daemonset.apps/kube-flannel-ds-ppc64le created
daemonset.apps/kube-flannel-ds-s390x created



Step 13 - Join worker nodes to master(only run on worker)
In the Step 10 we generated the token and kubeadm join command.

kubeadm join 100.0.0.1:6443 --token 457x4z.73b8paxxxxxckwwk2 \ --discovery-token-ca-cert-hash sha256:cca3de1a7aa03294c88ffa9b1ba4a7f1e1f6xxxxxxxxxxxxxe00731b2be5617d80 


W0423 19:27:00.344480   18268 join.go:346] preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.
preflight] Running pre-flight checks
	WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/
preflight] Reading configuration from the cluster...
preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'
kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.18" ConfigMap in the kube-system namespace
kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
kubelet-start] Starting the kubelet
kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.

Step 14 - Check the nodes status(only run on master)

To check the status of the nodes use
kubectl get nodes


NAME     STATUS   ROLES    AGE   VERSION
master   Ready    master   26m   v1.18.2
worker   Ready    <none>   63s   v1.18.2
==============================================
If you get message as following after Reboot the Ubuntu then do following ..
vagrant@master:~$ kubectl get nodes
The connection to the server 100.0.0.1:6443 was refused - did you specify the right host or port?
vagrant@master:~$

swapoff -a
exit
strace -eopenat kubectl version

and you can type kubectl get nodes again.

vagrant@master:~$ kubectl get nodes
NAME     STATUS   ROLES                  AGE   VERSION
master   Ready    control-plane,master   22h   v1.21.0
worker   Ready    <none>                 19h   v1.21.0
vagrant@master:~$ 

OR
Make a script auto start master node after reboot :
vi /etc/rc.local

Copy and paste:
#!/bin/bash
swapoff -a
systemctl start kubelet
docker start (docker ps -a -q)
docker start (docker ps -a -q)

Change mode:
chmod +x /etc/rc.local
